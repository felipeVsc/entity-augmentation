{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c12723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from openai) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/felipe/Documents/code/dolap/venv/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp314-cp314-macosx_11_0_arm64.whl (318 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, distro, openai\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [openai]━━━━\u001b[0m \u001b[32m3/4\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 jiter-0.12.0 openai-2.8.1 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84474d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Read the API key\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "client = OpenAI(\n",
    "  api_key=API_KEY\n",
    ")\n",
    "\n",
    "\n",
    "inputTest = \"\"\"\"\n",
    "This is the attributes extracted from the database for you to enrich the properties\n",
    "\n",
    "name: \"Guarulhos Airport\"\n",
    "iata: \"GRU\"\n",
    "country: \"Brazil\"\n",
    "city: \"Sao Paulo\"\n",
    "\"\"\"\n",
    "\n",
    "promptTest = \"\"\"\"\n",
    "# Identity\n",
    "\n",
    "You are an assistant that enrichs entities from a database for analytics by identifying the corresponding real-world entity and adding new trustworthy factual attributes. These attributes will be transformed into property:value pairs in a property-graph database.\n",
    "\n",
    "# Instructions\n",
    "\n",
    "1. From the input node (property:value pairs), infer the most likely real-world entity and its entity class (Person, Organization, Location, Product, Country). The entity can be either nodes or relationship between two real-world entities.\n",
    "2. Add the most factual information you can confidently verify for the entity class. Prioritize core, verifiable facts (dates, identifiers, official names, locations, standardized codes, market share, estimated revenue).\n",
    "3. Use consistent property names and information across entities of the same class. Try to make entities share the most amount of high-value information.\n",
    "4. Do not repeat information that already exists in the input\n",
    "\n",
    "# Output format\n",
    "\n",
    "Out a CSV with header `property,value`.\n",
    "These will be related only to properties of nodes.\n",
    "If no facts can be verified, output only the header row.\n",
    "\"\"\"\n",
    "\n",
    "folder_path = \"../prompts/\"\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "texts = []\n",
    "\n",
    "for filename in files:\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            texts.append(content)\n",
    "\n",
    "modelName = \"gpt-5-2025-08-07\"\n",
    "# gpt-5-2025-08-07\n",
    "for index,prompt in enumerate(texts):\n",
    "\n",
    "  response = client.responses.create(\n",
    "    model=modelName,\n",
    "    instructions=prompt,\n",
    "    input=inputTest,\n",
    "    store=True,\n",
    "  )\n",
    "\n",
    "  output_path = \"../outputs/\"+f\"{modelName}_{files[index]}\"\n",
    "  with open(output_path, \"w\", encoding=\"utf-8\") as outputFile:\n",
    "    outputFile.write(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3bf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
